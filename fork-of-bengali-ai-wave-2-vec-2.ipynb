{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a131f3",
   "metadata": {
    "papermill": {
     "duration": 0.004484,
     "end_time": "2023-10-14T12:59:15.712138",
     "exception": false,
     "start_time": "2023-10-14T12:59:15.707654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- These inference notebook is based on @nischaydnk's [notebook](https://www.kaggle.com/code/nischaydnk/bengali-finetuning-baseline-wav2vec2-inference). If it's helpful to you, please upvote his firstly.\n",
    "- Running this notebook you can score 0.338 on leaderboard.\n",
    "- This model is trained around 8 epochs with 1e-4 learning rate on the data of [Common Voice 13](http://www.kaggle.com/datasets/umongsain/common-voice-13-bengali-normalized) provided by @UMONG SAIN and the competition data 'valid' part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183caad6",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-10-14T12:59:15.721482Z",
     "iopub.status.busy": "2023-10-14T12:59:15.721041Z",
     "iopub.status.idle": "2023-10-14T13:00:21.390354Z",
     "shell.execute_reply": "2023-10-14T13:00:21.387833Z"
    },
    "papermill": {
     "duration": 65.676764,
     "end_time": "2023-10-14T13:00:21.392692",
     "exception": false,
     "start_time": "2023-10-14T12:59:15.715928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jiwer/\r\n",
      "jiwer/jiwer-2.3.0-py3-none-any.whl\r\n",
      "jiwer/python-Levenshtein-0.12.2.tar.gz\r\n",
      "jiwer/setuptools-65.3.0-py3-none-any.whl\r\n",
      "Looking in links: ./\r\n",
      "Processing ./jiwer/jiwer-2.3.0-py3-none-any.whl\r\n",
      "INFO: pip is looking at multiple versions of jiwer to determine which version is compatible with other requirements. This could take a while.\r\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement python-Levenshtein==0.12.2 (from jiwer) (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for python-Levenshtein==0.12.2\u001b[0m\u001b[31m\r\n",
      "\u001b[0mnormalizer/\r\n",
      "normalizer/bnunicodenormalizer-0.0.24.tar.gz\r\n",
      "Looking in links: ./\r\n",
      "Processing ./normalizer/bnunicodenormalizer-0.0.24.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: bnunicodenormalizer\r\n",
      "  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.0.24-py3-none-any.whl size=17628 sha256=6531327b41d150598935f6d9d0d076b190c6d8e1b48cd791afafe4ecc3eebe44\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/78/d7/75/6986dc3616718f950b80e3bd79a796ef618eaef6cd800e7909\r\n",
      "Successfully built bnunicodenormalizer\r\n",
      "Installing collected packages: bnunicodenormalizer\r\n",
      "Successfully installed bnunicodenormalizer-0.0.24\r\n",
      "pyctcdecode/\r\n",
      "pyctcdecode/hypothesis-6.54.4-py3-none-any.whl\r\n",
      "pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl\r\n",
      "pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl\r\n",
      "pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl\r\n",
      "pyctcdecode/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\n",
      "pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl\r\n",
      "pyctcdecode/pygtrie-2.5.0.tar.gz\r\n",
      "Looking in links: ./\r\n",
      "Processing ./pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl\r\n",
      "Installing collected packages: attrs\r\n",
      "  Attempting uninstall: attrs\r\n",
      "    Found existing installation: attrs 23.1.0\r\n",
      "    Uninstalling attrs-23.1.0:\r\n",
      "      Successfully uninstalled attrs-23.1.0\r\n",
      "Successfully installed attrs-22.1.0\r\n",
      "Looking in links: ./\r\n",
      "Processing ./pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl\r\n",
      "Installing collected packages: exceptiongroup\r\n",
      "  Attempting uninstall: exceptiongroup\r\n",
      "    Found existing installation: exceptiongroup 1.1.1\r\n",
      "    Uninstalling exceptiongroup-1.1.1:\r\n",
      "      Successfully uninstalled exceptiongroup-1.1.1\r\n",
      "Successfully installed exceptiongroup-1.0.0rc9\r\n",
      "Looking in links: ./\r\n",
      "Processing ./pyctcdecode/hypothesis-6.54.4-py3-none-any.whl\r\n",
      "Installing collected packages: hypothesis\r\n",
      "Successfully installed hypothesis-6.54.4\r\n",
      "Looking in links: ./\r\n",
      "\u001b[31mERROR: numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mLooking in links: ./\r\n",
      "Processing ./pyctcdecode/pygtrie-2.5.0.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pygtrie\r\n",
      "  Building wheel for pygtrie (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pygtrie: filename=pygtrie-2.5.0-py3-none-any.whl size=20945 sha256=df9c78910dc8fc63c4eabaa061d74d85b28865c9293ead857fced62b3da7bac3\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/78/28/09/b62c97a3e77102645c7ecc78c97580ad57090b1eee5438d6ac\r\n",
      "Successfully built pygtrie\r\n",
      "Installing collected packages: pygtrie\r\n",
      "Successfully installed pygtrie-2.5.0\r\n",
      "Looking in links: ./\r\n",
      "Processing ./pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl\r\n",
      "sortedcontainers is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Looking in links: ./\r\n",
      "Processing ./pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl\r\n",
      "Installing collected packages: pyctcdecode\r\n",
      "Successfully installed pyctcdecode-0.4.0\r\n",
      "pypikenlm/\r\n",
      "pypikenlm/pypi-kenlm-0.1.20220713.tar.gz\r\n",
      "Looking in links: ./\r\n",
      "Processing ./pypikenlm/pypi-kenlm-0.1.20220713.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pypi-kenlm\r\n",
      "  Building wheel for pypi-kenlm (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pypi-kenlm: filename=pypi_kenlm-0.1.20220713-cp310-cp310-linux_x86_64.whl size=333264 sha256=44ee6d062ea5c836f7fdb69a2d21e2a3dc9ef959ea0b320ed917803fe00a8acd\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/7a/db/27645fac296d5d5ba5c461b1af834eebc0ba4643290dbc5476\r\n",
      "Successfully built pypi-kenlm\r\n",
      "Installing collected packages: pypi-kenlm\r\n",
      "Successfully installed pypi-kenlm-0.1.20220713\r\n"
     ]
    }
   ],
   "source": [
    "!cp -r ../input/python-packages2 ./\n",
    "\n",
    "!tar xvfz ./python-packages2/jiwer.tgz\n",
    "!pip install ./jiwer/jiwer-2.3.0-py3-none-any.whl -f ./ --no-index\n",
    "!tar xvfz ./python-packages2/normalizer.tgz\n",
    "!pip install ./normalizer/bnunicodenormalizer-0.0.24.tar.gz -f ./ --no-index\n",
    "!tar xvfz ./python-packages2/pyctcdecode.tgz\n",
    "!pip install ./pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n",
    "!pip install ./pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl -f ./ --no-index --no-deps\n",
    "!pip install ./pyctcdecode/hypothesis-6.54.4-py3-none-any.whl -f ./ --no-index --no-deps\n",
    "!pip install ./pyctcdecode/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl -f ./ --no-index --no-deps\n",
    "!pip install ./pyctcdecode/pygtrie-2.5.0.tar.gz -f ./ --no-index --no-deps\n",
    "!pip install ./pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n",
    "!pip install ./pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n",
    "\n",
    "!tar xvfz ./python-packages2/pypikenlm.tgz\n",
    "!pip install ./pypikenlm/pypi-kenlm-0.1.20220713.tar.gz -f ./ --no-index --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e2c14be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-14T13:00:21.410830Z",
     "iopub.status.busy": "2023-10-14T13:00:21.410080Z",
     "iopub.status.idle": "2023-10-14T13:00:22.370144Z",
     "shell.execute_reply": "2023-10-14T13:00:22.368876Z"
    },
    "papermill": {
     "duration": 0.971515,
     "end_time": "2023-10-14T13:00:22.372517",
     "exception": false,
     "start_time": "2023-10-14T13:00:21.401002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm -r python-packages2 jiwer normalizer pyctcdecode pypikenlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93cd46b7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-14T13:00:22.389740Z",
     "iopub.status.busy": "2023-10-14T13:00:22.389433Z",
     "iopub.status.idle": "2023-10-14T13:00:36.105309Z",
     "shell.execute_reply": "2023-10-14T13:00:36.104285Z"
    },
    "papermill": {
     "duration": 13.727478,
     "end_time": "2023-10-14T13:00:36.107567",
     "exception": false,
     "start_time": "2023-10-14T13:00:22.380089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import typing as tp\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import pandas as pd\n",
    "import pyctcdecode\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import librosa\n",
    "\n",
    "import pyctcdecode\n",
    "import kenlm\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ProcessorWithLM, Wav2Vec2ForCTC\n",
    "from bnunicodenormalizer import Normalizer\n",
    "\n",
    "import cloudpickle as cpkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38f3ef2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-14T13:00:36.125664Z",
     "iopub.status.busy": "2023-10-14T13:00:36.125252Z",
     "iopub.status.idle": "2023-10-14T13:00:36.130678Z",
     "shell.execute_reply": "2023-10-14T13:00:36.129645Z"
    },
    "papermill": {
     "duration": 0.01679,
     "end_time": "2023-10-14T13:00:36.132603",
     "exception": false,
     "start_time": "2023-10-14T13:00:36.115813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT = Path.cwd().parent\n",
    "INPUT = ROOT / \"input\"\n",
    "DATA = INPUT / \"bengaliai-speech\"\n",
    "TRAIN = DATA / \"train_mp3s\"\n",
    "TEST = DATA / \"test_mp3s\"\n",
    "\n",
    "SAMPLING_RATE = 16_000\n",
    "MODEL_PATH = INPUT / \"bengali-ai-wave-2-vec-3\"\n",
    "LM_PATH = INPUT / \"arijitx-full-model/wav2vec2-xls-r-300m-bengali/language_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0f574b",
   "metadata": {
    "papermill": {
     "duration": 0.007659,
     "end_time": "2023-10-14T13:00:36.148620",
     "exception": false,
     "start_time": "2023-10-14T13:00:36.140961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### load model, processor, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dce6077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-14T13:00:36.166233Z",
     "iopub.status.busy": "2023-10-14T13:00:36.165853Z",
     "iopub.status.idle": "2023-10-14T13:00:47.487072Z",
     "shell.execute_reply": "2023-10-14T13:00:47.485751Z"
    },
    "papermill": {
     "duration": 11.33176,
     "end_time": "2023-10-14T13:00:47.488483",
     "exception": true,
     "start_time": "2023-10-14T13:00:36.156723",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:53: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/wav2vec2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">processing_wav2vec2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">51</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 48 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@classmethod</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 49 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>, pretrained_model_name_or_path, **kwargs):                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 50 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 51 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().from_pretrained(pretrained_model_name_or_path, **kwargs)        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 52 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">OSError</span>:                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 53 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>warnings.warn(                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 54 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Loading a tokenizer inside {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">} from a config that does not\"</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">processing_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">184</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">181 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">[`~feature_extraction_utils.FeatureExtractionMixin.from_pretrained`] and</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">182 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">[`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`].</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">183 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>184 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>args = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwarg   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">185 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>(*args)                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">186 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">187 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@classmethod</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">processing_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">228</span> in                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_arguments_from_pretrained</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">226 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>attribute_class = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(transformers_module, class_name)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>228 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, *   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">229 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> args                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">230 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">231 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@property</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_auto.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">712</span> in     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">709 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> tokenizer_class_fast.from_pretrained(pretrained_model_name_or_pat   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">710 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">711 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> tokenizer_class_py <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>712 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> tokenizer_class_py.from_pretrained(pretrained_model_name_or_p   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">713 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">714 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">715 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"This tokenizer cannot be instantiated. Please make sure you hav</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_utils_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1809</span> in          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1806 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1807 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1808 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">all</span>(full_file_name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> full_file_name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> resolved_vocab_files.values(  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1809 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">EnvironmentError</span>(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1810 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Can't load tokenizer for '{</span>pretrained_model_name_or_path<span style=\"color: #808000; text-decoration-color: #808000\">}'. If you wer</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1811 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"'https://huggingface.co/models', make sure you don't have a local direc</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1812 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Otherwise, make sure '{</span>pretrained_model_name_or_path<span style=\"color: #808000; text-decoration-color: #808000\">}' is the correct </span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OSError: </span>Can't load tokenizer for <span style=\"color: #008000; text-decoration-color: #008000\">'/kaggle/input/bengali-ai-wave-2-vec-3'</span>. If you were trying to load it from \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://huggingface.co/models'</span>, make sure you don't have a local directory with the same name. Otherwise, make \n",
       "sure <span style=\"color: #008000; text-decoration-color: #008000\">'/kaggle/input/bengali-ai-wave-2-vec-3'</span> is the correct path to a directory containing all relevant files for a\n",
       "Wav2Vec2CTCTokenizer tokenizer.\n",
       "\n",
       "<span style=\"font-style: italic\">During handling of the above exception, another exception occurred:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>model = Wav2Vec2ForCTC.from_pretrained(MODEL_PATH)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2 processor = Wav2Vec2Processor.from_pretrained(MODEL_PATH)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/wav2vec2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">processing_wav2vec2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">63</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 60 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 61 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 62 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(pretrained_mode   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 63 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(pretrained_model_name_or_pa   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 64 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 65 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>(feature_extractor=feature_extractor, tokenizer=tokenizer)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 66 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_utils_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1809</span> in          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1806 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1807 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1808 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">all</span>(full_file_name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> full_file_name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> resolved_vocab_files.values(  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1809 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">EnvironmentError</span>(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1810 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Can't load tokenizer for '{</span>pretrained_model_name_or_path<span style=\"color: #808000; text-decoration-color: #808000\">}'. If you wer</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1811 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"'https://huggingface.co/models', make sure you don't have a local direc</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1812 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Otherwise, make sure '{</span>pretrained_model_name_or_path<span style=\"color: #808000; text-decoration-color: #808000\">}' is the correct </span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OSError: </span>Can't load tokenizer for <span style=\"color: #008000; text-decoration-color: #008000\">'/kaggle/input/bengali-ai-wave-2-vec-3'</span>. If you were trying to load it from \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://huggingface.co/models'</span>, make sure you don't have a local directory with the same name. Otherwise, make \n",
       "sure <span style=\"color: #008000; text-decoration-color: #008000\">'/kaggle/input/bengali-ai-wave-2-vec-3'</span> is the correct path to a directory containing all relevant files for a\n",
       "Wav2Vec2CTCTokenizer tokenizer.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/wav2vec2/\u001b[0m\u001b[1;33mprocessing_wav2vec2.py\u001b[0m:\u001b[94m51\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 48 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@classmethod\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 49 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mfrom_pretrained\u001b[0m(\u001b[96mcls\u001b[0m, pretrained_model_name_or_path, **kwargs):                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 50 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 51 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96msuper\u001b[0m().from_pretrained(pretrained_model_name_or_path, **kwargs)        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mOSError\u001b[0m:                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   │   │   \u001b[0mwarnings.warn(                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 54 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mLoading a tokenizer inside \u001b[0m\u001b[33m{\u001b[0m\u001b[96mcls\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m from a config that does not\u001b[0m\u001b[33m\"\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mprocessing_utils.py\u001b[0m:\u001b[94m184\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m181 \u001b[0m\u001b[2;33m│   │   │   │   \u001b[0m\u001b[33m[`~feature_extraction_utils.FeatureExtractionMixin.from_pretrained`] and\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m182 \u001b[0m\u001b[2;33m│   │   │   │   \u001b[0m\u001b[33m[`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`].\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m183 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m184 \u001b[2m│   │   \u001b[0margs = \u001b[96mcls\u001b[0m._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwarg   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m185 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mcls\u001b[0m(*args)                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m186 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m187 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@classmethod\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mprocessing_utils.py\u001b[0m:\u001b[94m228\u001b[0m in                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_get_arguments_from_pretrained\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m225 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m226 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mattribute_class = \u001b[96mgetattr\u001b[0m(transformers_module, class_name)                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m228 \u001b[2m│   │   │   \u001b[0margs.append(attribute_class.from_pretrained(pretrained_model_name_or_path, *   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m229 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m args                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m230 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m231 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@property\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/\u001b[0m\u001b[1;33mtokenization_auto.py\u001b[0m:\u001b[94m712\u001b[0m in     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m709 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m tokenizer_class_fast.from_pretrained(pretrained_model_name_or_pat   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m710 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m711 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m tokenizer_class_py \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m712 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m tokenizer_class_py.from_pretrained(pretrained_model_name_or_p   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m713 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m714 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m715 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mThis tokenizer cannot be instantiated. Please make sure you hav\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtokenization_utils_base.py\u001b[0m:\u001b[94m1809\u001b[0m in          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1806 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1807 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1808 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mall\u001b[0m(full_file_name \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[94mfor\u001b[0m full_file_name \u001b[95min\u001b[0m resolved_vocab_files.values(  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1809 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mEnvironmentError\u001b[0m(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1810 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCan\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt load tokenizer for \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpretrained_model_name_or_path\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m. If you wer\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1811 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m'\u001b[0m\u001b[33mhttps://huggingface.co/models\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, make sure you don\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt have a local direc\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1812 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mOtherwise, make sure \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpretrained_model_name_or_path\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m is the correct \u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOSError: \u001b[0mCan't load tokenizer for \u001b[32m'/kaggle/input/bengali-ai-wave-2-vec-3'\u001b[0m. If you were trying to load it from \n",
       "\u001b[32m'https://huggingface.co/models'\u001b[0m, make sure you don't have a local directory with the same name. Otherwise, make \n",
       "sure \u001b[32m'/kaggle/input/bengali-ai-wave-2-vec-3'\u001b[0m is the correct path to a directory containing all relevant files for a\n",
       "Wav2Vec2CTCTokenizer tokenizer.\n",
       "\n",
       "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mmodel = Wav2Vec2ForCTC.from_pretrained(MODEL_PATH)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2 processor = Wav2Vec2Processor.from_pretrained(MODEL_PATH)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/wav2vec2/\u001b[0m\u001b[1;33mprocessing_wav2vec2.py\u001b[0m:\u001b[94m63\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 60 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 61 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 62 \u001b[0m\u001b[2m│   │   │   \u001b[0mfeature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(pretrained_mode   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 63 \u001b[2m│   │   │   \u001b[0mtokenizer = Wav2Vec2CTCTokenizer.from_pretrained(pretrained_model_name_or_pa   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mcls\u001b[0m(feature_extractor=feature_extractor, tokenizer=tokenizer)           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 66 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtokenization_utils_base.py\u001b[0m:\u001b[94m1809\u001b[0m in          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1806 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1807 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1808 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mall\u001b[0m(full_file_name \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[94mfor\u001b[0m full_file_name \u001b[95min\u001b[0m resolved_vocab_files.values(  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1809 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mEnvironmentError\u001b[0m(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1810 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCan\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt load tokenizer for \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpretrained_model_name_or_path\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m. If you wer\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1811 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m'\u001b[0m\u001b[33mhttps://huggingface.co/models\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, make sure you don\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt have a local direc\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1812 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mOtherwise, make sure \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpretrained_model_name_or_path\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m is the correct \u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOSError: \u001b[0mCan't load tokenizer for \u001b[32m'/kaggle/input/bengali-ai-wave-2-vec-3'\u001b[0m. If you were trying to load it from \n",
       "\u001b[32m'https://huggingface.co/models'\u001b[0m, make sure you don't have a local directory with the same name. Otherwise, make \n",
       "sure \u001b[32m'/kaggle/input/bengali-ai-wave-2-vec-3'\u001b[0m is the correct path to a directory containing all relevant files for a\n",
       "Wav2Vec2CTCTokenizer tokenizer.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_PATH)\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc3bdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T16:56:28.157892Z",
     "iopub.status.busy": "2023-10-13T16:56:28.15724Z",
     "iopub.status.idle": "2023-10-13T16:57:03.876671Z",
     "shell.execute_reply": "2023-10-13T16:57:03.875657Z",
     "shell.execute_reply.started": "2023-10-13T16:56:28.157858Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k: v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n",
    "\n",
    "decoder = pyctcdecode.build_ctcdecoder(\n",
    "    list(sorted_vocab_dict.keys()),\n",
    "    str(LM_PATH / \"5gram.bin\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9c311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T16:57:03.878554Z",
     "iopub.status.busy": "2023-10-13T16:57:03.877879Z",
     "iopub.status.idle": "2023-10-13T16:57:03.889979Z",
     "shell.execute_reply": "2023-10-13T16:57:03.889052Z",
     "shell.execute_reply.started": "2023-10-13T16:57:03.878497Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    decoder=decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae13ab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d0bd51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T16:57:03.892438Z",
     "iopub.status.busy": "2023-10-13T16:57:03.891271Z",
     "iopub.status.idle": "2023-10-13T16:57:03.903113Z",
     "shell.execute_reply": "2023-10-13T16:57:03.90202Z",
     "shell.execute_reply.started": "2023-10-13T16:57:03.892403Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BengaliSRTestDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        audio_paths: list[str],\n",
    "        sampling_rate: int\n",
    "    ):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.sampling_rate = sampling_rate\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        audio_path = self.audio_paths[index]\n",
    "        sr = self.sampling_rate\n",
    "        w = librosa.load(audio_path, sr=sr, mono=False)[0]\n",
    "        \n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee3df14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T16:57:03.905205Z",
     "iopub.status.busy": "2023-10-13T16:57:03.90431Z",
     "iopub.status.idle": "2023-10-13T16:57:03.92785Z",
     "shell.execute_reply": "2023-10-13T16:57:03.926757Z",
     "shell.execute_reply.started": "2023-10-13T16:57:03.905174Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(DATA / \"sample_submission.csv\", dtype={\"id\": str})\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625141ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T16:57:03.931795Z",
     "iopub.status.busy": "2023-10-13T16:57:03.931434Z",
     "iopub.status.idle": "2023-10-13T16:57:03.936525Z",
     "shell.execute_reply": "2023-10-13T16:57:03.935329Z",
     "shell.execute_reply.started": "2023-10-13T16:57:03.931768Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_audio_paths = [str(TEST / f\"{aid}.mp3\") for aid in test[\"id\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee2f809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T16:57:03.93869Z",
     "iopub.status.busy": "2023-10-13T16:57:03.937847Z",
     "iopub.status.idle": "2023-10-13T16:57:03.94726Z",
     "shell.execute_reply": "2023-10-13T16:57:03.94638Z",
     "shell.execute_reply.started": "2023-10-13T16:57:03.93866Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = BengaliSRTestDataset(\n",
    "    test_audio_paths, SAMPLING_RATE\n",
    ")\n",
    "\n",
    "collate_func = partial(\n",
    "    processor_with_lm.feature_extractor,\n",
    "    return_tensors=\"pt\", sampling_rate=SAMPLING_RATE,\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=16, shuffle=False,\n",
    "    num_workers=2, collate_fn=collate_func, drop_last=False,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e7e79",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b8d29d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T16:57:03.94898Z",
     "iopub.status.busy": "2023-10-13T16:57:03.948459Z",
     "iopub.status.idle": "2023-10-13T16:57:03.983709Z",
     "shell.execute_reply": "2023-10-13T16:57:03.982743Z",
     "shell.execute_reply.started": "2023-10-13T16:57:03.948942Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eda852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T16:57:03.986085Z",
     "iopub.status.busy": "2023-10-13T16:57:03.984992Z",
     "iopub.status.idle": "2023-10-13T16:57:08.800076Z",
     "shell.execute_reply": "2023-10-13T16:57:08.799134Z",
     "shell.execute_reply.started": "2023-10-13T16:57:03.986049Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "model = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0219e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T16:57:08.80223Z",
     "iopub.status.busy": "2023-10-13T16:57:08.801565Z",
     "iopub.status.idle": "2023-10-13T16:57:21.614723Z",
     "shell.execute_reply": "2023-10-13T16:57:21.613743Z",
     "shell.execute_reply.started": "2023-10-13T16:57:08.802196Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_sentence_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        x = batch[\"input_values\"]\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "            y = model(x).logits\n",
    "        y = y.detach().cpu().numpy()\n",
    "        \n",
    "        for l in y:  \n",
    "            sentence = processor_with_lm.decode(l, beam_width=512).text\n",
    "            pred_sentence_list.append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ce865",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426dc10b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T16:57:21.620915Z",
     "iopub.status.busy": "2023-10-13T16:57:21.618542Z",
     "iopub.status.idle": "2023-10-13T16:57:21.629788Z",
     "shell.execute_reply": "2023-10-13T16:57:21.628623Z",
     "shell.execute_reply.started": "2023-10-13T16:57:21.620878Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bnorm = Normalizer()\n",
    "\n",
    "def postprocess(sentence):\n",
    "    period_set = set([\".\", \"?\", \"!\", \"।\"])\n",
    "    _words = [bnorm(word)['normalized']  for word in sentence.split()]\n",
    "    sentence = \" \".join([word for word in _words if word is not None])\n",
    "    try:\n",
    "        if sentence[-1] not in period_set:\n",
    "            sentence+=\"।\"\n",
    "    except:\n",
    "        # print(sentence)\n",
    "        sentence = \"।\"\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031add3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T16:57:21.636442Z",
     "iopub.status.busy": "2023-10-13T16:57:21.633958Z",
     "iopub.status.idle": "2023-10-13T16:57:21.704238Z",
     "shell.execute_reply": "2023-10-13T16:57:21.703529Z",
     "shell.execute_reply.started": "2023-10-13T16:57:21.63641Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp_pred_sentence_list = [postprocess(s) for s in tqdm(pred_sentence_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ddf64b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T16:57:21.709847Z",
     "iopub.status.busy": "2023-10-13T16:57:21.707868Z",
     "iopub.status.idle": "2023-10-13T16:57:21.735267Z",
     "shell.execute_reply": "2023-10-13T16:57:21.734415Z",
     "shell.execute_reply.started": "2023-10-13T16:57:21.709816Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[\"sentence\"] = pp_pred_sentence_list\n",
    "\n",
    "test.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "display(test.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 102.72732,
   "end_time": "2023-10-14T13:00:50.219997",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-14T12:59:07.492677",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
