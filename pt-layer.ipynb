{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/gpreda/pt-layer?scriptVersionId=127010048\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"a51615cf","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-24T11:05:18.802173Z","iopub.status.busy":"2023-04-24T11:05:18.801732Z","iopub.status.idle":"2023-04-24T11:05:21.62255Z","shell.execute_reply":"2023-04-24T11:05:21.620754Z"},"papermill":{"duration":2.830063,"end_time":"2023-04-24T11:05:21.626032","exception":false,"start_time":"2023-04-24T11:05:18.795969","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","\n","\n","class FeaturesLinear(torch.nn.Module):\n","\n","    def __init__(self, field_dims, output_dim=1):\n","        super().__init__()\n","        self.fc = torch.nn.Embedding(sum(field_dims), output_dim)\n","        self.bias = torch.nn.Parameter(torch.zeros((output_dim,)))\n","        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        :param x: Long tensor of size ``(batch_size, num_fields)``\n","        \"\"\"\n","        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n","        return torch.sum(self.fc(x), dim=1) + self.bias\n","\n","\n","class FeaturesEmbedding(torch.nn.Module):\n","\n","    def __init__(self, field_dims, embed_dim):\n","        super().__init__()\n","        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\n","        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n","        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        :param x: Long tensor of size ``(batch_size, num_fields)``\n","        \"\"\"\n","        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n","        return self.embedding(x)\n","\n","\n","class FieldAwareFactorizationMachine(torch.nn.Module):\n","\n","    def __init__(self, field_dims, embed_dim):\n","        super().__init__()\n","        self.num_fields = len(field_dims)\n","        self.embeddings = torch.nn.ModuleList([\n","            torch.nn.Embedding(sum(field_dims), embed_dim) for _ in range(self.num_fields)\n","        ])\n","        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n","        for embedding in self.embeddings:\n","            torch.nn.init.xavier_uniform_(embedding.weight.data)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        :param x: Long tensor of size ``(batch_size, num_fields)``\n","        \"\"\"\n","        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n","        xs = [self.embeddings[i](x) for i in range(self.num_fields)]\n","        ix = list()\n","        for i in range(self.num_fields - 1):\n","            for j in range(i + 1, self.num_fields):\n","                ix.append(xs[j][:, i] * xs[i][:, j])\n","        ix = torch.stack(ix, dim=1)\n","        return ix\n","\n","\n","class FactorizationMachine(torch.nn.Module):\n","\n","    def __init__(self, reduce_sum=True):\n","        super().__init__()\n","        self.reduce_sum = reduce_sum\n","\n","    def forward(self, x):\n","        \"\"\"\n","        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n","        \"\"\"\n","        square_of_sum = torch.sum(x, dim=1) ** 2\n","        sum_of_square = torch.sum(x ** 2, dim=1)\n","        ix = square_of_sum - sum_of_square\n","        if self.reduce_sum:\n","            ix = torch.sum(ix, dim=1, keepdim=True)\n","        return 0.5 * ix\n","\n","\n","class MultiLayerPerceptron(torch.nn.Module):\n","\n","    def __init__(self, input_dim, embed_dims, dropout, output_layer=True):\n","        super().__init__()\n","        layers = list()\n","        for embed_dim in embed_dims:\n","            layers.append(torch.nn.Linear(input_dim, embed_dim))\n","            layers.append(torch.nn.BatchNorm1d(embed_dim))\n","            layers.append(torch.nn.ReLU())\n","            layers.append(torch.nn.Dropout(p=dropout))\n","            input_dim = embed_dim\n","        if output_layer:\n","            layers.append(torch.nn.Linear(input_dim, 1))\n","        self.mlp = torch.nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        :param x: Float tensor of size ``(batch_size, embed_dim)``\n","        \"\"\"\n","        return self.mlp(x)\n","\n","\n","class InnerProductNetwork(torch.nn.Module):\n","\n","    def forward(self, x):\n","        \"\"\"\n","        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n","        \"\"\"\n","        num_fields = x.shape[1]\n","        row, col = list(), list()\n","        for i in range(num_fields - 1):\n","            for j in range(i + 1, num_fields):\n","                row.append(i), col.append(j)\n","        return torch.sum(x[:, row] * x[:, col], dim=2)\n","\n","\n","class OuterProductNetwork(torch.nn.Module):\n","\n","    def __init__(self, num_fields, embed_dim, kernel_type='mat'):\n","        super().__init__()\n","        num_ix = num_fields * (num_fields - 1) // 2\n","        if kernel_type == 'mat':\n","            kernel_shape = embed_dim, num_ix, embed_dim\n","        elif kernel_type == 'vec':\n","            kernel_shape = num_ix, embed_dim\n","        elif kernel_type == 'num':\n","            kernel_shape = num_ix, 1\n","        else:\n","            raise ValueError('unknown kernel type: ' + kernel_type)\n","        self.kernel_type = kernel_type\n","        self.kernel = torch.nn.Parameter(torch.zeros(kernel_shape))\n","        torch.nn.init.xavier_uniform_(self.kernel.data)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n","        \"\"\"\n","        num_fields = x.shape[1]\n","        row, col = list(), list()\n","        for i in range(num_fields - 1):\n","            for j in range(i + 1, num_fields):\n","                row.append(i), col.append(j)\n","        p, q = x[:, row], x[:, col]\n","        if self.kernel_type == 'mat':\n","            kp = torch.sum(p.unsqueeze(1) * self.kernel, dim=-1).permute(0, 2, 1)\n","            return torch.sum(kp * q, -1)\n","        else:\n","            return torch.sum(p * q * self.kernel.unsqueeze(0), -1)\n","\n","\n","class CrossNetwork(torch.nn.Module):\n","\n","    def __init__(self, input_dim, num_layers):\n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.w = torch.nn.ModuleList([\n","            torch.nn.Linear(input_dim, 1, bias=False) for _ in range(num_layers)\n","        ])\n","        self.b = torch.nn.ParameterList([\n","            torch.nn.Parameter(torch.zeros((input_dim,))) for _ in range(num_layers)\n","        ])\n","\n","    def forward(self, x):\n","        \"\"\"\n","        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n","        \"\"\"\n","        x0 = x\n","        for i in range(self.num_layers):\n","            xw = self.w[i](x)\n","            x = x0 * xw + self.b[i] + x\n","        return x\n","\n","\n","class AttentionalFactorizationMachine(torch.nn.Module):\n","\n","    def __init__(self, embed_dim, attn_size, dropouts):\n","        super().__init__()\n","        self.attention = torch.nn.Linear(embed_dim, attn_size)\n","        self.projection = torch.nn.Linear(attn_size, 1)\n","        self.fc = torch.nn.Linear(embed_dim, 1)\n","        self.dropouts = dropouts\n","\n","    def forward(self, x):\n","        \"\"\"\n","        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n","        \"\"\"\n","        num_fields = x.shape[1]\n","        row, col = list(), list()\n","        for i in range(num_fields - 1):\n","            for j in range(i + 1, num_fields):\n","                row.append(i), col.append(j)\n","        p, q = x[:, row], x[:, col]\n","        inner_product = p * q\n","        attn_scores = F.relu(self.attention(inner_product))\n","        attn_scores = F.softmax(self.projection(attn_scores), dim=1)\n","        attn_scores = F.dropout(attn_scores, p=self.dropouts[0], training=self.training)\n","        attn_output = torch.sum(attn_scores * inner_product, dim=1)\n","        attn_output = F.dropout(attn_output, p=self.dropouts[1], training=self.training)\n","        return self.fc(attn_output)\n","\n","\n","class CompressedInteractionNetwork(torch.nn.Module):\n","\n","    def __init__(self, input_dim, cross_layer_sizes, split_half=True):\n","        super().__init__()\n","        self.num_layers = len(cross_layer_sizes)\n","        self.split_half = split_half\n","        self.conv_layers = torch.nn.ModuleList()\n","        prev_dim, fc_input_dim = input_dim, 0\n","        for i in range(self.num_layers):\n","            cross_layer_size = cross_layer_sizes[i]\n","            self.conv_layers.append(torch.nn.Conv1d(input_dim * prev_dim, cross_layer_size, 1,\n","                                                    stride=1, dilation=1, bias=True))\n","            if self.split_half and i != self.num_layers - 1:\n","                cross_layer_size //= 2\n","            prev_dim = cross_layer_size\n","            fc_input_dim += prev_dim\n","        self.fc = torch.nn.Linear(fc_input_dim, 1)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n","        \"\"\"\n","        xs = list()\n","        x0, h = x.unsqueeze(2), x\n","        for i in range(self.num_layers):\n","            x = x0 * h.unsqueeze(1)\n","            batch_size, f0_dim, fin_dim, embed_dim = x.shape\n","            x = x.view(batch_size, f0_dim * fin_dim, embed_dim)\n","            x = F.relu(self.conv_layers[i](x))\n","            if self.split_half and i != self.num_layers - 1:\n","                x, h = torch.split(x, x.shape[1] // 2, dim=1)\n","            else:\n","                h = x\n","            xs.append(x)\n","        return self.fc(torch.sum(torch.cat(xs, dim=1), 2))\n","\n","\n","class AnovaKernel(torch.nn.Module):\n","\n","    def __init__(self, order, reduce_sum=True):\n","        super().__init__()\n","        self.order = order\n","        self.reduce_sum = reduce_sum\n","\n","    def forward(self, x):\n","        \"\"\"\n","        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n","        \"\"\"\n","        batch_size, num_fields, embed_dim = x.shape\n","        a_prev = torch.ones((batch_size, num_fields + 1, embed_dim), dtype=torch.float).to(x.device)\n","        for t in range(self.order):\n","            a = torch.zeros((batch_size, num_fields + 1, embed_dim), dtype=torch.float).to(x.device)\n","            a[:, t+1:, :] += x[:, t:, :] * a_prev[:, t:-1, :]\n","            a = torch.cumsum(a, dim=1)\n","            a_prev = a\n","        if self.reduce_sum:\n","            return torch.sum(a[:, -1, :], dim=-1, keepdim=True)\n","        else:\n","            return a[:, -1, :]"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":14.496984,"end_time":"2023-04-24T11:05:22.762163","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-04-24T11:05:08.265179","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}