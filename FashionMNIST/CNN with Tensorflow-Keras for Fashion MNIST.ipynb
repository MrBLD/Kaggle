{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "805a97911f01abb36ff8414d8d6aec9293e4fb85"
   },
   "source": [
    "<h1><center><font size=\"6\">CNN with Keras for Fashion MNIST</font></center></h1>\n",
    "\n",
    "\n",
    "<img src=\"https://kaggle2.blob.core.windows.net/datasets-images/2243/3791/9384af51de8baa77f6320901f53bd26b/dataset-card.png\" width=\"400\"></img>\n",
    "\n",
    "\n",
    "# <a id='0'>Content</a>\n",
    "\n",
    "- <a href='#1'>Introduction</a>  \n",
    "- <a href='#2'>Load packages</a>  \n",
    "- <a href='#3'>Read and prepare the data</a>  \n",
    "- <a href='#4'>Data exploration</a>\n",
    "- <a href='#5'>Prepare the model</a>  \n",
    "- <a href='#6'>Prediction accuracy</a>  \n",
    "- <a href='#7'>Conclusions</a>\n",
    "- <a href='#8'>References</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b1c16628c2f62a18e1dc2068e1d67d7003922b1"
   },
   "source": [
    "# <a id=\"1\">Introduction</a>  \n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "\n",
    "## Content\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total.   \n",
    "\n",
    "Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255.   \n",
    "\n",
    "The training and test data sets have 785 columns.   \n",
    "\n",
    "The first column consists of the class labels (see above), and represents the article of clothing. \n",
    "\n",
    "The rest of 784 columns (1-785) contain the pixel-values of the associated image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a708dc52b2e5990e2247ed573d50d0f6933b730"
   },
   "source": [
    "# <a id=\"2\">Load packages</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "2defa674e4e6d0e7371df92e7d1f388fc5c14bb6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e17fd2539412442ddb3ecacf84366ddd62faf836"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "d7a44bfc7a28df7026241c4a7e047298446f1554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train-images-idx3-ubyte', 'train-labels-idx1-ubyte', 't10k-labels-idx1-ubyte', 'fashion-mnist_train.csv', 't10k-images-idx3-ubyte', 'fashion-mnist_test.csv']\n"
     ]
    }
   ],
   "source": [
    "IMG_ROWS = 28\n",
    "IMG_COLS = 28\n",
    "NUM_CLASSES = 10\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 2018\n",
    "#Model\n",
    "NO_EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "IS_LOCAL = False\n",
    "\n",
    "import os\n",
    "\n",
    "if(IS_LOCAL):\n",
    "    PATH=\"../input/fashionmnist/\"\n",
    "else:\n",
    "    PATH=\"../input/\"\n",
    "print(os.listdir(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f49d65b4af77e87ab34b6854850619911cff1e6d"
   },
   "source": [
    "# <a id=\"3\">Read and prepare the data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "a9c3148fda056ecc88570b302f5185064d5e9fc8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = IMG_ROWS, IMG_COLS\n",
    "num_classes = NUM_CLASSES\n",
    "\n",
    "# data preprocessing\n",
    "def data_preprocessing(raw):\n",
    "    out_y = keras.utils.to_categorical(raw.label, num_classes)\n",
    "    num_images = raw.shape[0]\n",
    "    x_as_array = raw.values[:,1:]\n",
    "    x_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1)\n",
    "    out_x = x_shaped_array / 255\n",
    "    return out_x, out_y\n",
    "\n",
    "train_file = PATH+\"fashion-mnist_train.csv\"\n",
    "test_file  = PATH+\"fashion-mnist_test.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_file)\n",
    "test_data = pd.read_csv(train_file)\n",
    "\n",
    "# prepare the data\n",
    "X, y = data_preprocessing(train_data)\n",
    "X_test, y_test = data_preprocessing(test_data)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "290f8f38b2f64dfd1bd3432eb1e9a101dbbaf4e5"
   },
   "source": [
    "# <a id=\"4\">Data exploration</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "41ff999272c27ad5bbc457ea0770590b7a7d6770",
    "collapsed": true
   },
   "source": [
    "This section is not developed yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd9405b5a3fe0c7bd5bebe0616190a8cf26d2811"
   },
   "source": [
    "# <a id=\"3\">Prepare the model</a>\n",
    "\n",
    "\n",
    "We will use a **Sequential** model.\n",
    "* The **Sequential** model is a linear stack of layers. It can be first initialized and then we add layers using **add** method or we can add all layers at init stage. The layers added are as follows:\n",
    "\n",
    "* **Conv2D** is a 2D Convolutional layer (i.e. spatial convolution over images). The parameters used are:\n",
    " * filters - the number of filters (Kernels) used with this layer; here filters = 32;\n",
    " * kernel_size - the dimmension of the Kernel: (3 x 3);\n",
    " * activation - is the activation function used, in this case `relu`;\n",
    " * kernel_initializer - the function used for initializing the kernel;\n",
    " * input_shape - is the shape of the image presented to the CNN: in our case is 28 x 28\n",
    " The input and output of the **Conv2D** is a 4D tensor.\n",
    " \n",
    "* **MaxPooling2D** is a Max pooling operation for spatial data. Parameters used here are:\n",
    " * *pool_size*, in this case (2,2), representing the factors by which to downscale in both directions;\n",
    " \n",
    "* **Dropout**. Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting. The parameter used is:\n",
    " * *rate*, set here to 0.25. \n",
    " \n",
    "* **Conv2D** with the following parameters:\n",
    " * filters: 64;\n",
    " * kernel_size : (3 x 3);\n",
    " * activation : `relu`;\n",
    " \n",
    "* **MaxPooling2D** with parameter:\n",
    " * *pool_size* : (2,2);\n",
    "\n",
    "* **Dropout**. with parameter:\n",
    " * *rate* : 0.25;\n",
    " \n",
    "* **Conv2D** with the following parameters:\n",
    " * filters: 128;\n",
    " * kernel_size : (3 x 3);\n",
    " * activation : `relu`;\n",
    "\n",
    "* **Dropout**. with parameter:\n",
    " * *rate* : 0.4;\n",
    " \n",
    "* **Flatten**. This layer Flattens the input. Does not affect the batch size. It is used without parameters;\n",
    "\n",
    "* **Dense**. This layer is a regular fully-connected NN layer. It is used without parameters;\n",
    " * units - this is a positive integer, with the meaning: dimensionality of the output space; in this case is: 128;\n",
    " * activation - activation function : `relu`;\n",
    "\n",
    "* **Dropout**. with parameter:\n",
    " * *rate* : 0.3;\n",
    " \n",
    "* **Dense**. This is the final layer (fully connected). It is used with the parameters:\n",
    " * units: the number of classes (in our case 10);\n",
    " * activation : `softmax`; for this final layer it is used `softmax` activation (standard for multiclass classification)\n",
    " \n",
    "\n",
    "Then we compile the model, specifying as well the following parameters:\n",
    "* **loss**;\n",
    "* **optimizer**;\n",
    "* **metrics**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "e31836cd5ec9d86340485404b8f613d1f574aca4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "# Add convolution 2D\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ecb450d70539a62fb310bb7ed44849d2d01481ee"
   },
   "source": [
    "## Show the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "b4b923b11ceaf4a97677f8e24265e3e97ae1653b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 241,546\n",
      "Trainable params: 241,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "68a2e932241f29e52a3150b3fcf3fe9c21243be2"
   },
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "400494b7e0525069175625422e8c300bd7b41c51",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 7s 146us/step - loss: 0.7786 - acc: 0.7074 - val_loss: 0.5086 - val_acc: 0.8123\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.5010 - acc: 0.8139 - val_loss: 0.3918 - val_acc: 0.8601\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.4202 - acc: 0.8436 - val_loss: 0.3326 - val_acc: 0.8805\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.3783 - acc: 0.8620 - val_loss: 0.3028 - val_acc: 0.8912\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.3507 - acc: 0.8719 - val_loss: 0.2875 - val_acc: 0.8952\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 6s 123us/step - loss: 0.3287 - acc: 0.8790 - val_loss: 0.2837 - val_acc: 0.8968\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 6s 123us/step - loss: 0.3110 - acc: 0.8862 - val_loss: 0.2755 - val_acc: 0.8996\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 6s 124us/step - loss: 0.3020 - acc: 0.8906 - val_loss: 0.2625 - val_acc: 0.9043\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 6s 124us/step - loss: 0.2904 - acc: 0.8933 - val_loss: 0.2603 - val_acc: 0.9053\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2825 - acc: 0.8951 - val_loss: 0.2568 - val_acc: 0.9048\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2744 - acc: 0.8995 - val_loss: 0.2434 - val_acc: 0.9102\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.2681 - acc: 0.9015 - val_loss: 0.2422 - val_acc: 0.9123\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2633 - acc: 0.9019 - val_loss: 0.2551 - val_acc: 0.9029\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.2554 - acc: 0.9044 - val_loss: 0.2373 - val_acc: 0.9101\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2528 - acc: 0.9063 - val_loss: 0.2365 - val_acc: 0.9105\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2495 - acc: 0.9072 - val_loss: 0.2401 - val_acc: 0.9132\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2441 - acc: 0.9089 - val_loss: 0.2298 - val_acc: 0.9158\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.2412 - acc: 0.9101 - val_loss: 0.2357 - val_acc: 0.9128\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.2406 - acc: 0.9096 - val_loss: 0.2325 - val_acc: 0.9156\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2300 - acc: 0.9123 - val_loss: 0.2325 - val_acc: 0.9153\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2356 - acc: 0.9111 - val_loss: 0.2278 - val_acc: 0.9167\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2291 - acc: 0.9136 - val_loss: 0.2249 - val_acc: 0.9184\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.2252 - acc: 0.9157 - val_loss: 0.2278 - val_acc: 0.9162\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.2244 - acc: 0.9166 - val_loss: 0.2291 - val_acc: 0.9167\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2186 - acc: 0.9184 - val_loss: 0.2259 - val_acc: 0.9175\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2207 - acc: 0.9163 - val_loss: 0.2209 - val_acc: 0.9203\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2182 - acc: 0.9174 - val_loss: 0.2280 - val_acc: 0.9203\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2163 - acc: 0.9186 - val_loss: 0.2210 - val_acc: 0.9217\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2122 - acc: 0.9185 - val_loss: 0.2238 - val_acc: 0.9197\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2086 - acc: 0.9209 - val_loss: 0.2232 - val_acc: 0.9192\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2107 - acc: 0.9198 - val_loss: 0.2222 - val_acc: 0.9186\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.2086 - acc: 0.9220 - val_loss: 0.2210 - val_acc: 0.9181\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2074 - acc: 0.9220 - val_loss: 0.2195 - val_acc: 0.9200\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2030 - acc: 0.9220 - val_loss: 0.2183 - val_acc: 0.9226\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.2054 - acc: 0.9226 - val_loss: 0.2163 - val_acc: 0.9227\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.2024 - acc: 0.9234 - val_loss: 0.2288 - val_acc: 0.9179\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1973 - acc: 0.9253 - val_loss: 0.2170 - val_acc: 0.9212\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2008 - acc: 0.9237 - val_loss: 0.2213 - val_acc: 0.9204\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1954 - acc: 0.9262 - val_loss: 0.2166 - val_acc: 0.9214\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1962 - acc: 0.9259 - val_loss: 0.2198 - val_acc: 0.9224\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1963 - acc: 0.9260 - val_loss: 0.2196 - val_acc: 0.9217\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1954 - acc: 0.9259 - val_loss: 0.2170 - val_acc: 0.9223\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1936 - acc: 0.9268 - val_loss: 0.2242 - val_acc: 0.9199\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1901 - acc: 0.9273 - val_loss: 0.2302 - val_acc: 0.9172\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1891 - acc: 0.9283 - val_loss: 0.2239 - val_acc: 0.9221\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1905 - acc: 0.9272 - val_loss: 0.2290 - val_acc: 0.9206\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1924 - acc: 0.9263 - val_loss: 0.2174 - val_acc: 0.9236\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1872 - acc: 0.9282 - val_loss: 0.2213 - val_acc: 0.9222\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1852 - acc: 0.9298 - val_loss: 0.2235 - val_acc: 0.9222\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1887 - acc: 0.9286 - val_loss: 0.2198 - val_acc: 0.9215\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1880 - acc: 0.9289 - val_loss: 0.2231 - val_acc: 0.9212\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1827 - acc: 0.9298 - val_loss: 0.2332 - val_acc: 0.9202\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1837 - acc: 0.9311 - val_loss: 0.2210 - val_acc: 0.9241\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1865 - acc: 0.9300 - val_loss: 0.2142 - val_acc: 0.9236\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1835 - acc: 0.9305 - val_loss: 0.2138 - val_acc: 0.9253\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 6s 123us/step - loss: 0.1796 - acc: 0.9324 - val_loss: 0.2231 - val_acc: 0.9238\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1865 - acc: 0.9290 - val_loss: 0.2151 - val_acc: 0.9247\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1800 - acc: 0.9325 - val_loss: 0.2220 - val_acc: 0.9219\n",
      "Epoch 59/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1808 - acc: 0.9317 - val_loss: 0.2181 - val_acc: 0.9236\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1787 - acc: 0.9313 - val_loss: 0.2234 - val_acc: 0.9229\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1779 - acc: 0.9321 - val_loss: 0.2253 - val_acc: 0.9215\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1843 - acc: 0.9313 - val_loss: 0.2171 - val_acc: 0.9240\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1782 - acc: 0.9317 - val_loss: 0.2210 - val_acc: 0.9209\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1745 - acc: 0.9324 - val_loss: 0.2242 - val_acc: 0.9233\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1778 - acc: 0.9321 - val_loss: 0.2203 - val_acc: 0.9241\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1750 - acc: 0.9337 - val_loss: 0.2192 - val_acc: 0.9243\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1746 - acc: 0.9334 - val_loss: 0.2244 - val_acc: 0.9257\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1719 - acc: 0.9337 - val_loss: 0.2231 - val_acc: 0.9237\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1768 - acc: 0.9331 - val_loss: 0.2289 - val_acc: 0.9211\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1698 - acc: 0.9345 - val_loss: 0.2205 - val_acc: 0.9237\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1745 - acc: 0.9346 - val_loss: 0.2238 - val_acc: 0.9211\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1725 - acc: 0.9349 - val_loss: 0.2231 - val_acc: 0.9235\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1754 - acc: 0.9344 - val_loss: 0.2174 - val_acc: 0.9243\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1735 - acc: 0.9342 - val_loss: 0.2226 - val_acc: 0.9226\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1710 - acc: 0.9359 - val_loss: 0.2186 - val_acc: 0.9240\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1701 - acc: 0.9349 - val_loss: 0.2167 - val_acc: 0.9255\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1730 - acc: 0.9351 - val_loss: 0.2186 - val_acc: 0.9226\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1680 - acc: 0.9358 - val_loss: 0.2148 - val_acc: 0.9249\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1679 - acc: 0.9357 - val_loss: 0.2152 - val_acc: 0.9263\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1698 - acc: 0.9364 - val_loss: 0.2145 - val_acc: 0.9242\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1653 - acc: 0.9370 - val_loss: 0.2165 - val_acc: 0.9264\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1684 - acc: 0.9369 - val_loss: 0.2229 - val_acc: 0.9261\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1707 - acc: 0.9353 - val_loss: 0.2191 - val_acc: 0.9243\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1665 - acc: 0.9374 - val_loss: 0.2248 - val_acc: 0.9228\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1668 - acc: 0.9374 - val_loss: 0.2180 - val_acc: 0.9235\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1642 - acc: 0.9371 - val_loss: 0.2199 - val_acc: 0.9249\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1637 - acc: 0.9374 - val_loss: 0.2240 - val_acc: 0.9228\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1661 - acc: 0.9362 - val_loss: 0.2188 - val_acc: 0.9245\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1672 - acc: 0.9361 - val_loss: 0.2189 - val_acc: 0.9218\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1651 - acc: 0.9377 - val_loss: 0.2347 - val_acc: 0.9172\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1671 - acc: 0.9378 - val_loss: 0.2168 - val_acc: 0.9247\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1627 - acc: 0.9386 - val_loss: 0.2176 - val_acc: 0.9251\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1637 - acc: 0.9380 - val_loss: 0.2182 - val_acc: 0.9264\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1604 - acc: 0.9384 - val_loss: 0.2245 - val_acc: 0.9245\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1642 - acc: 0.9380 - val_loss: 0.2177 - val_acc: 0.9244\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1617 - acc: 0.9400 - val_loss: 0.2192 - val_acc: 0.9231\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1621 - acc: 0.9386 - val_loss: 0.2152 - val_acc: 0.9241\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1600 - acc: 0.9393 - val_loss: 0.2157 - val_acc: 0.9246\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1584 - acc: 0.9395 - val_loss: 0.2172 - val_acc: 0.9239\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1568 - acc: 0.9392 - val_loss: 0.2179 - val_acc: 0.9243\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NO_EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8699df44bc0a95f1a43a201d3dd566746d87173f"
   },
   "source": [
    "### Evaluate the model score\n",
    "\n",
    "We calculate the test loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "b9e2bb7f25b02d491e34dd0d6d05943e287ae369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.100464833015576\n",
      "Test accuracy: 0.96715\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d779b0e47b8263370031c292a231b69decad374"
   },
   "source": [
    "# <a id=\"6\">Prediction accuracy</a>\n",
    "\n",
    "We evaluate the model accuracy based on the predicted values for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_uuid": "e519f82cc29b0dd8c5145d612da3eb496e2b321d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Class 0       0.94      0.94      0.94      6000\n",
      "    Class 1       1.00      0.99      1.00      6000\n",
      "    Class 2       0.94      0.96      0.95      6000\n",
      "    Class 3       0.96      0.98      0.97      6000\n",
      "    Class 4       0.96      0.94      0.95      6000\n",
      "    Class 5       1.00      1.00      1.00      6000\n",
      "    Class 6       0.91      0.89      0.90      6000\n",
      "    Class 7       0.98      0.99      0.99      6000\n",
      "    Class 8       1.00      1.00      1.00      6000\n",
      "    Class 9       0.99      0.98      0.99      6000\n",
      "\n",
      "avg / total       0.97      0.97      0.97     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get the predictions for the test data\n",
    "predicted_classes = model.predict_classes(X_test)\n",
    "\n",
    "#get the indices to be plotted\n",
    "y_true = test_data.iloc[:, 0]\n",
    "correct = np.nonzero(predicted_classes==y_true)[0]\n",
    "incorrect = np.nonzero(predicted_classes!=y_true)[0]\n",
    "\n",
    "\n",
    "\n",
    "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "print(classification_report(y_true, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e24053db4dbfec25fd1b90391586d7ce6bc32988"
   },
   "source": [
    "# <a id=\"7\">Conclusions</a>\n",
    "\n",
    "The best accuracy is obtained for Class 1, Class 5, Class 8, Class 9  and Class 7. Worst accuracy is for Class 6.\n",
    "\n",
    "The recall is highest for Class 8, Class 5 and smallest for Class 6 and Class 4.\n",
    "\n",
    "f1-score is highest for Class 1, Class 5 and Class 8 and smallest for Class 6 followed by Class 4 and Class 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b45e3422fb9507da66ce7af67a97b54e7fa7683"
   },
   "source": [
    "# <a id=\"8\">References</a>\n",
    "\n",
    "[1] Fashion MNIST, An MNIST-like dataset of 70,000 28x28 labeled fashion images, https://www.kaggle.com/zalando-research/fashionmnist  \n",
    "[2] DanB, CollinMoris, Deep Learning From Scratch, https://www.kaggle.com/dansbecker/deep-learning-from-scratch  \n",
    "[3] DanB, Dropout and Strides for Larger Models, https://www.kaggle.com/dansbecker/dropout-and-strides-for-larger-models  \n",
    "[4] BGO, CNN with Keras, https://www.kaggle.com/bugraokcu/cnn-with-keras  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
